{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae8d053",
   "metadata": {},
   "source": [
    "# Train DistilBert on the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5bf7ff-5dcd-414b-8ab1-f0f38817fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, AutoModelForMaskedLM\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1dd1c",
   "metadata": {},
   "source": [
    "Load Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = load_dataset(\"csv\", data_files=\"data\\\\cvpr_data.csv\")\n",
    "abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24b27ff",
   "metadata": {},
   "source": [
    "Load pretrained dislroberta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4af1d-d946-44ae-9214-105523aa9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc710e",
   "metadata": {},
   "source": [
    "Get the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2688e50-3546-4213-9f15-d7d6a49962de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a2735",
   "metadata": {},
   "source": [
    "Tokenize the abstract (pad to max length, truncate if longer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa255c59-da21-4289-bb68-cce068115981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"abstract\"], padding=\"max_length\", max_length=256, truncation=True,)\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = abstracts.map(\n",
    "    tokenize_function, batched=True, remove_columns=abstracts[\"train\"].features.keys()\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0e9e4-7528-4f9d-a9b9-f8eae7ac6605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenized_datasets[\"train\"].select([1])[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e2726-7a6b-45c6-b258-9c872edc9b3b",
   "metadata": {},
   "source": [
    "data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343c6f9-afa3-41cc-84d5-724aaf4932e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7055587-3b69-4606-9b40-76ae16dedfb7",
   "metadata": {},
   "source": [
    "Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2245a-c427-46bd-954a-f31720d32804",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 9_000\n",
    "\n",
    "downsampled_dataset = tokenized_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, seed=123456,\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3febe63-3602-4247-bd8b-99ee17d2d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-cvpr\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    "    num_train_epochs = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abed75-6e0c-4ac9-bbc3-8848199078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92298a92",
   "metadata": {},
   "source": [
    "Calculate model perplexity before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c01266-6f8e-45a2-8318-47f1bdc96df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {np.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c305cce",
   "metadata": {},
   "source": [
    "Train model and check perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62398c5e-e6c0-4665-9b57-af455da30df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deea5a76-da17-42ff-98bd-aa088346b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {np.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22ff13",
   "metadata": {},
   "source": [
    "Save the model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d8803-7767-493c-9c10-186db6164936",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"{model_name}-finetuned-cvpr\")\n",
    "tokenizer.save_pretrained(f\"{model_name}-finetuned-cvpr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5bb167dcc8e0362259233268f8aabb06284b5cd30446df487de294e1c7e8a6f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
